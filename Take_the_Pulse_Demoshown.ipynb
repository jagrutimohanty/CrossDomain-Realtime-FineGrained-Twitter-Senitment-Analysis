{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Take_the_Pulse_Demoshown.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagrutimohanty/CrossDomain-Realtime-FineGrained-Twitter-Senitment-Analysis/blob/main/Take_the_Pulse_Demoshown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr_26JZvVUCZ",
        "outputId": "0e15f761-9b70-46a8-a6fe-bc48af2b387d"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DIR = '/content/drive/Shareddrives/255/Project'\n",
        "if os.getcwd() != DIR:\n",
        "  os.chdir(DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp0hvLYRQpBN"
      },
      "source": [
        "# **TAKE THE PULSE - DEMO**\n",
        "\n",
        "## **Fine Grained Sentiment Analysis with Twitter**\n",
        "\n",
        "For our demo we'll showcase our model's predictions in two ways, offline sentiment analysis prediction as well as realtime predictions\n",
        "\n",
        "## Offline Analysis\n",
        "We'll do this in five steps\n",
        "* fetch tweets about movie hashtags from the Twitter API. \n",
        "* run the tweets through a preprocessing pipeline\n",
        "* encode them using BERT like we did for our training data\n",
        "* pass them through our best performing model to get predictions\n",
        "* present the predictions on a bar graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRXlgpooU8Vz"
      },
      "source": [
        "### Step 1: Fetching the Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfn8h3jzwpZR"
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRpccpVNxoMX"
      },
      "source": [
        "# consumer_key = ''\n",
        "consumer_key = ''\n",
        "# consumer_secret = ''\n",
        "consumer_secret = ''\n",
        "# access_token = ''\n",
        "access_token =  ''\n",
        "# access_token_secret = ''\n",
        "access_token_secret = ''\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key,consumer_secret) \n",
        "auth.set_access_token(access_token, access_token_secret) \n",
        "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0VBMgLE8PIy"
      },
      "source": [
        "# FYI, there's a rate limiter on this API call, when we hit the rate limit, the\n",
        "# function sleeps for a set amount of time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "now=datetime.today().now()\n",
        "prev=now-timedelta(days=150)\n",
        "now=now.strftime(\"%Y-%m-%d\")\n",
        "prev=prev.strftime(\"%Y-%m-%d\") \n",
        "# LockHerUp negative sentiments\n",
        "# hamilton, TGIF positive sentiments\n",
        "# MacbookAir, iphone12, MacMini, MacOSBigSur for product sentiment\n",
        "# iphone12ProMax, GalaxyS20Ultra, Pixel4XL\n",
        "tweetObjects = tweepy.Cursor(\n",
        "    api.search, \n",
        "    q=['#iphone12'], \n",
        "    lang=\"en\", \n",
        "    since=prev,\n",
        "    until=now, \n",
        "    result_type=\"recent\",\n",
        "    tweet_mode='extended'\n",
        "    ).items(2000)\n",
        "tweets_df = pd.DataFrame([tweetObj.full_text for tweetObj in tweetObjects], columns=['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5LFMciLcx_p"
      },
      "source": [
        "For the purposes of our demo we saved the tweets onto Google drive because this API call is rate limited, we don't want to keep fetching the same tweets over and over again and hit the rate limit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M98qL-vycyTi"
      },
      "source": [
        "tweets_df.to_csv('./tweets/MacbookAir.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "WYHFBnLB2hfi",
        "outputId": "7acd1a06-3648-4844-825e-9e42c165e7b2"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "tweets_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>900</th>\n",
              "      <td>RT @MarkhorTechUrdu: The unboxing of very first Macbook air with Apple M1 chip #m1Chip @apple #MacBookAir https://t.co/8fVfQJVKw0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>RT @Poorvika_Mobile: Experience Power that's in the Air with the 13.3\" #MacBookAir from #Apple available for just ₹72,990 with ₹6,000 #HDFC…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Just noticed that every time I hit the #shuffle button in #AppleMusic on a #MacBookPro or #MacBookAir it just plays first track then normal play. It highlights shuffle but doesn’t actually #shuffle @Apple @AppleSupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>DONATIONS ARE DOUBLED TODAY!!  #GivingTuesday #AdventCalendar #distancelearning #disney #Apple #macbookair #December1st  Check out my classroom on @DonorsChoose! I'd love your help to bring my project to life:  https://t.co/DqIxnxizX7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>@Apple analyst Ming-Chi Kuo believes that as part of Apple's mini LED push, the company will release a pair of new #MacBookPro models in 2021 with the technology — and a \"more affordable\" #MacBookAir in 2022. @appleinsider @Mike_Wuerthele \\nhttps://t.co/Fr6zOjkYPK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                         text\n",
              "900  RT @MarkhorTechUrdu: The unboxing of very first Macbook air with Apple M1 chip #m1Chip @apple #MacBookAir https://t.co/8fVfQJVKw0                                                                                                                                       \n",
              "862  RT @Poorvika_Mobile: Experience Power that's in the Air with the 13.3\" #MacBookAir from #Apple available for just ₹72,990 with ₹6,000 #HDFC…                                                                                                                            \n",
              "57   Just noticed that every time I hit the #shuffle button in #AppleMusic on a #MacBookPro or #MacBookAir it just plays first track then normal play. It highlights shuffle but doesn’t actually #shuffle @Apple @AppleSupport                                              \n",
              "277  DONATIONS ARE DOUBLED TODAY!!  #GivingTuesday #AdventCalendar #distancelearning #disney #Apple #macbookair #December1st  Check out my classroom on @DonorsChoose! I'd love your help to bring my project to life:  https://t.co/DqIxnxizX7                              \n",
              "167  @Apple analyst Ming-Chi Kuo believes that as part of Apple's mini LED push, the company will release a pair of new #MacBookPro models in 2021 with the technology — and a \"more affordable\" #MacBookAir in 2022. @appleinsider @Mike_Wuerthele \\nhttps://t.co/Fr6zOjkYPK"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWtFnWERAjDy"
      },
      "source": [
        "### Step 2: Tweets Preprocessing\n",
        "\n",
        "We remove all links since they wont add any semantic value to the encoding, we also remove the hashtags and the @mentions as well as the 'RTs' for retweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzIndkQq08NX"
      },
      "source": [
        "Input Tweet Text\n",
        "<br>\n",
        ">`@DaveedDiggs @annas_tea_ I shall Daveed! Just because you asked and were so INCREDIBLE in #Hamilton #BOOM my… https://t.co/0Ccg3Tu9KD`\n",
        "<br> \n",
        "\n",
        "Preprocessed Tweet text\n",
        "<br>\n",
        ">`tea i shall daveed just because you asked and were so incredible in my` \n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD8_BZSoAvIi"
      },
      "source": [
        "import re,string\n",
        "\n",
        "def strip_links(text):\n",
        "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
        "    links         = re.findall(link_regex, text)\n",
        "    for link in links:\n",
        "        text = text.replace(link[0], ', ')    \n",
        "    return text\n",
        "\n",
        "def strip_all_entities(text):\n",
        "    entity_prefixes = ['@','#']\n",
        "    for separator in  string.punctuation:\n",
        "        if separator not in entity_prefixes :\n",
        "            text = text.replace(separator,' ')\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        word = word.strip()\n",
        "        if word:\n",
        "            if word[0] not in entity_prefixes:\n",
        "                words.append(word)\n",
        "    text = ' '.join(words)\n",
        "    return text.replace('RT ', '').lower()\n",
        "\n",
        "def preprocess_tweets(s):\n",
        "  return strip_all_entities(strip_links(s))\n",
        "\n",
        "tweets_df['text'] = tweets_df ['text'].apply(preprocess_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1BoDPnp3D_b"
      },
      "source": [
        "We also remove tweets that are only punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYmiOTSam21Z"
      },
      "source": [
        "remove_invalid_phrases = lambda s: s.strip(string.punctuation) != ''\n",
        "tweets_df = tweets_df[tweets_df['text'].apply(remove_invalid_phrases).to_list()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbZ8-RIILOyu"
      },
      "source": [
        "We might have tweets that have no text after all our pre-processing, so let's filter out such tweets if any"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JCJ14eMLOXr",
        "outputId": "758afd8d-3df1-44ac-ef35-33822a753991"
      },
      "source": [
        "tweets_df = tweets_df[tweets_df['text'] != '']\n",
        "tweets_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWroGsVkJ1RT"
      },
      "source": [
        "### Step 3: Tweets BERT Encoding\n",
        "\n",
        "We now run the cleaned tweets through a Sentence Bert encoder. We use a publicly available pretrained model. `distilbert-base-nli-stsb-mean-tokens`, that is based on the paper *Sentence Embeddings using Siamese BERT Networks* by Nils Reimer and Iryna Gurevyh https://arxiv.org/abs/1908.10084\n",
        "\n",
        "Sentence BERT outputs a vector of shape (768,) for each tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4O-YnpZ7RtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc2ed10-633f-44ea-b186-b2ff4290ec3d"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/5a/6e41e8383913dd2ba923cdcd02be2e03911595f4d2f9de559ecbed80d2d3/sentence-transformers-0.3.9.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
            "\u001b[?25hCollecting transformers<3.6.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 41.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 34.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<3.6.0,>=3.1.0->sentence-transformers) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.9-cp36-none-any.whl size=101036 sha256=78056648d7d18269bbb7d4363c6508e93e01dbbf5ccc670a69f041e19de92327\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/89/43/f2f5bc00b03ef9724b0f6254a97eaf159a4c4ddc024b33e07a\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=e6788d090f57a169b607a12d69fe0a549942cbd89d8bbb6961adbcdb685fd23f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.9 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0vfjmgmcEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a81cc2-b64e-4232-f5ed-5c2cd2a2d151"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "encodings = sbert_model.encode(tweets_df['text'].to_numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:18<00:00, 22.4MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii_-PGuMrKtk"
      },
      "source": [
        "### Step 4: Predict the sentiment aka \"Take the Pulse\"\n",
        "\n",
        "We'll load our best performing SVM Classfier and predict the sentiment of the tweets.\n",
        "\n",
        "> This classifier does include a scikit learn standard scaler in its pipeline that normalizes the vectors before making predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3pz2RxQsV8O"
      },
      "source": [
        "from joblib import load\n",
        "# clf = load('./svm_models/rbf_512_80000_5.joblib')\n",
        "# balanced classifier that takes into account the imbalance in our dataset\n",
        "clf = load('./svm_models/rbf_80000_5_balanced.joblib')\n",
        "ovr_clf = load('./svm_models/ovr_rbf_80000_5_balanced.joblib')\n",
        "gcv_clf = load('./svm_models/rbf_80000_5_balanced_gcv.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqzOJpU1tIy-"
      },
      "source": [
        "We'll apply PCA to our tweet encoding vectors, by reducing it to a vector of shape (512,) for consistency with how our model was trained. This allows us to speed up the prediction while keeping over 99% of the variance in the original encodings array.\n",
        "\n",
        ">We don't need to apply standard sacling here since it's included as part of the pipelined classifier that we loaded into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCf6PO_ktdul",
        "outputId": "3d16e5f4-d874-4784-b4e6-0aa2d5d831ea"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=512)\n",
        "encodings = pca.fit_transform(encodings)\n",
        "print(np.sum(pca.explained_variance_ratio_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peVy__gTyvJW",
        "outputId": "732654a4-1903-41ae-cb97-d4900b2968f7"
      },
      "source": [
        "tweets_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PEC3U7Qu4jd"
      },
      "source": [
        "sentiments = clf.predict(encodings)\n",
        "ovr_sentiments = ovr_clf.predict(encodings)\n",
        "gcv_sentiments = gcv_clf.predict(encodings)\n",
        "tweets_df = tweets_df.assign(sentiments=sentiments)\n",
        "tweets_df = tweets_df.assign(ovr_sentiments=ovr_sentiments)\n",
        "tweets_df = tweets_df.assign(gcv_sentiments=gcv_sentiments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLbbGLkMvOgC"
      },
      "source": [
        "tweets_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2fJLlHGv417"
      },
      "source": [
        "### Step 5: Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOUF8bJATjNa"
      },
      "source": [
        "Map from label numbers to sentiment description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrLy_fwkTiVt"
      },
      "source": [
        "labels_map = {\n",
        "    '0': 'Very Negative :(',\n",
        "    '1': '- Negative -',\n",
        "    '2': 'Neutral :-|',\n",
        "    '3': '+ Positive +',\n",
        "    '4': 'Very Positive :)'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWeO4QefwBTn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counts = tweets_df['sentiments'].value_counts()\n",
        "x = [labels_map[str(idx)] for idx in counts.index]\n",
        "y = counts.to_numpy()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,2,2])\n",
        "ax.bar(x,y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "1zPY5vz32C_x",
        "outputId": "54ed1de3-17e1-4462-d74f-c6090c54147c"
      },
      "source": [
        "x = counts.index\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,2,2])\n",
        "ax.bar(x,y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIcRJXhBrfcZ"
      },
      "source": [
        "For multiple hashtags we can display the same information on a stacked bar graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zXIY0SG_MTn"
      },
      "source": [
        "## Online Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF3tCfkxeZdG"
      },
      "source": [
        "### Streaming Tweets\n",
        "\n",
        "We can also stream tweets from trending topics and get predictions on the sentiment of these tweets. So this runs through essentially the same pipeline as above, except the tweets are not obtained in a single REST API call but through a streaming API that listens until it reaches a minimum number of tweets and then runs the sentiment analysis pipeline with predictions at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylByRls8SE8d"
      },
      "source": [
        "# helper function to preprocess and predict the sentiment for a single tweet\n",
        "def take_the_pulse(tweet):\n",
        "  tweets = [tweet]\n",
        "  tweets = list(map(preprocess_tweets, tweets))\n",
        "  tweets = list(filter(remove_invalid_phrases, tweets))\n",
        "  encodings = sbert_model.encode(tweets)\n",
        "  sentiments = u_clf.predict(pca.transform(encodings))\n",
        "  return tweets[0], sentiments[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asuIEspHS9Fk"
      },
      "source": [
        "# helper function to get tweet's full text\n",
        "def get_full_text(tweet):\n",
        "    if 'retweeted_status' in tweet and 'extended_tweet' in tweet['retweeted_status']:\n",
        "        return tweet['retweeted_status']['extended_tweet']['full_text']\n",
        "    if 'extended_tweet' in tweet:\n",
        "        return tweet['extended_tweet']['full_text']\n",
        "    else:\n",
        "        return tweet['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC5eGTpHyk5D"
      },
      "source": [
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Global variables to keep track of when to close the stream\n",
        "tweet_count = 0\n",
        "MAX_TWEET_COUNT = 3\n",
        "\n",
        "# Tweet Stream Listener\n",
        "class StdOutListener(StreamListener):  \n",
        "    def on_data(self, data):\n",
        "        global tweet_count\n",
        "        global MAX_TWEETS\n",
        "        global stream\n",
        "        if tweet_count < MAX_TWEET_COUNT:\n",
        "            tweet = json.loads(data)    \n",
        "            if tweet['lang'] == \"en\":\n",
        "              text = get_full_text(tweet)\n",
        "              processed_text, sentiment = take_the_pulse(text)\n",
        "              print('==================================================')\n",
        "              print('Tweet: ', processed_text)\n",
        "              print('Predicted Sentiment: ', labels_map[str(sentiment)])\n",
        "              print('==================================================')\n",
        "              tweet_count += 1\n",
        "            return True\n",
        "        else:\n",
        "            stream.disconnect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlhK1e8uBmQO"
      },
      "source": [
        "# Handles Twitter authetification and the connection to Twitter Streaming API\n",
        "tweet_count = 0\n",
        "listener = StdOutListener()\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "stream = Stream(auth, listener, tweet_mode='extended')\n",
        "stream.filter(track=['#COVID19'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xSy3upFB5iv"
      },
      "source": [
        "### Trending Topics\n",
        "\n",
        "We'll try out our model with trending topics and see what results we get"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaD6ggjjQrRP"
      },
      "source": [
        "Fetch trending topics by location. For this cell we'll experiment with ID 1 which is the global ID for trending topics worldwide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7lj51MU2Y7y"
      },
      "source": [
        "# get tags by location\n",
        "# we'll use ID 1 and ID 2488042 \n",
        "GLOBAL_ID = 1\n",
        "SJ_ID = 2488042\n",
        "SF_ID = 2487956\n",
        "tags = api.trends_place(GLOBAL_ID)\n",
        "\n",
        "def top_k_tags(k, tags):\n",
        "  top_k = tags[0]['trends'][:k]\n",
        "  return [(tag['name'], tag['query'], tag['tweet_volume']) for tag in top_k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysBCKtgcQ6NR"
      },
      "source": [
        "Get the top 10 topics and their corresponding tweet volume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LiJ1SShE3QP",
        "outputId": "083e0fcb-406f-486d-8a30-c155659c653d"
      },
      "source": [
        "top10 = top_k_tags(10, tags)\n",
        "print(top10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('#WeLoveYouHyunjin', '%23WeLoveYouHyunjin', 105749), ('#HyunjinBestBoy', '%23HyunjinBestBoy', 98435), ('#REUNION', '%23REUNION', 17223), ('#ガチで欲しいもの5選', '%23%E3%82%AC%E3%83%81%E3%81%A7%E6%AC%B2%E3%81%97%E3%81%84%E3%82%82%E3%81%AE5%E9%81%B8', None), ('#RESONANCEwithNCT', '%23RESONANCEwithNCT', 158587), ('集計ミス', '%E9%9B%86%E8%A8%88%E3%83%9F%E3%82%B9', 10220), ('リンボマン', '%E3%83%AA%E3%83%B3%E3%83%9C%E3%83%9E%E3%83%B3', 17890), ('BTS vs BTS', '%22BTS+vs+BTS%22', 56844), ('soobin', 'soobin', 141159), ('محمد', '%D9%85%D8%AD%D9%85%D8%AF', 387472)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QDVZnrQmWbZb",
        "outputId": "13b7e5be-816c-428a-ed42-33a6050e6b32"
      },
      "source": [
        "hottest_topic_query = top10[0][0]\n",
        "if hottest_topic_query[0] != '#':\n",
        "  hottest_topic_query = '#' + hottest_topic_query\n",
        "hottest_topic_query"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#WeLoveYouHyunjin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep2C6plwRBqm"
      },
      "source": [
        "Set a stream to listen in for the tweets and predict their sentiment as they come in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcjAH7Eg2Z2R"
      },
      "source": [
        "tweet_count = 0\n",
        "listener = StdOutListener()\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "stream = Stream(auth, listener, tweet_mode='extended')\n",
        "stream.filter(track=[hottest_topic_query])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}