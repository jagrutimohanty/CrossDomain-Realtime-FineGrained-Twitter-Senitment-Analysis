{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Take_the_Pulse_Multiclass_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagrutimohanty/CrossDomain-Realtime-FineGrained-Twitter-Senitment-Analysis/blob/main/Take_the_Pulse_Multiclass_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diTs9EhWRQ2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81f5527-053b-40e8-a90a-0ac1b9d61023"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt85WkdWtH45"
      },
      "source": [
        "# **TAKE THE PULSE - MULTICLASS SVM**\n",
        "\n",
        "When dealing with high dimensional spaces, it's hard to beat SVMs. They are really effective in high dimensional spaces, not only that but are versatile in the decision boundaries through kernel functions. They also only need a subset of the training data to learn the decision boundary.\n",
        "\n",
        "For our task, we have vectors of shape (768, ) from BERT. We then do dimensionality reduction getting it down to (512,) while retaining ~99% of the original variance. We have ~180000 rows of data and are looking for boundaries to split it into five sentiment classes, that's where Multiclass SVMs come in.\n",
        "\n",
        "While SVMs were designed for binary classification tasks and not for multiclass classification tasks, there are workarounds to get multiclass predictions. We experimented with two of these in our project.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl6FOXIY2-3V"
      },
      "source": [
        "## One-vs-Rest Classifiers\n",
        "\n",
        "This involves splitting the multi-class dataset into multiple binary classification problems. A binary classifier is then trained on each of these problems separately and predicitons made using the model that is most confident\n",
        "\n",
        "For instance we have five sentiments that we're trying to predict in our data: Very Positive, Positive, Neutral, Negative and Very Negative.\n",
        "\n",
        "This can be split into five binary classification problems as follows\n",
        "* Very Positive Classification\n",
        "> Very Positive vs [*Positive, Neutral, Negative, Very Negative*]\n",
        "\n",
        "* Positive Classification\n",
        "> Positive vs [*Very Positive, Neutral, Negative, Very Negative*]\n",
        "\n",
        "* Neutral Classification\n",
        "> Neutral vs [*Very Positive, Positive, Negative, Very Negative*]\n",
        "\n",
        "* Negative Classification\n",
        "> Very Positive vs [*Very Positive, Positive, Neutral, Very Negative*]\n",
        "\n",
        "* Very Negative Classification\n",
        "> Very Positive vs [*Very Positive, Positive, Neutral, Negative*]\n",
        "\n",
        "This means that our model creates five classifiers. For each phrase in our training data or tweet later in test time, each classifier predicts a class membership probablity and then the argmax of these scores is used to predict the class\n",
        "\n",
        "We used two such variants of OVR on our training corpus, Sklearn's SVC that uses OVR by default for multiclass classification and we also used the OneVsRestClassifier wrapper around an SVC model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQPvSUR7Aiw6"
      },
      "source": [
        "Make sure we're in the right directory\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRApEeTd7j_3"
      },
      "source": [
        "import os \n",
        "\n",
        "DIR = '/content/drive/Shareddrives/255/Project'\n",
        "if os.getcwd() != DIR:\n",
        "  os.chdir(DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uaj1a4y9AnQR"
      },
      "source": [
        "Read in our data, we join the two dataframes, dictionary and sentiment labels on the phrase id and then use the combined dataframe to test our models. We're also loading in the BERT encodings of our phrases that we'll pass as input to our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tbsIr737gYb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('./cleaned_data/dictionary.csv')\n",
        "sentiment = pd.read_csv('./cleaned_data/sentiment_labels.txt', sep=\"|\")\n",
        "combined = pd.merge(data, \n",
        "                    sentiment, \n",
        "                    how='inner', \n",
        "                    left_on='id', \n",
        "                    right_on='phrase ids')\n",
        "df = combined[['phrase', 'sentiment values']]\n",
        "encodings = np.loadtxt('./cleaned_data/rt_bert_encodings.csv', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnmV8LUbBBXz"
      },
      "source": [
        "This is a helper function that maps the sentiment probabilities back to the five classes that we're predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqlEjMbo7to6"
      },
      "source": [
        "def assign_sentiment(val):\n",
        "  if val <= 0.2:\n",
        "    return 0\n",
        "  elif val <= 0.4:\n",
        "    return 1\n",
        "  elif val <= 0.6:\n",
        "    return 2\n",
        "  elif val <= 0.8:\n",
        "    return 3\n",
        "  return 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBmsgkoABKgi"
      },
      "source": [
        "We'll add our new sentiment column to our dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpd8Wykz7uje"
      },
      "source": [
        "labels = list(map(assign_sentiment, df['sentiment values'].to_numpy()))\n",
        "df = df.assign(labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQvMyqlNBPqT"
      },
      "source": [
        "Dimensionality reduction on the BERT encodings to get vectors of shape (512,)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjbmI1sa74UA",
        "outputId": "611c466d-3d00-432b-a824-ba0b46223f9b"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=512)\n",
        "labels = np.array(labels)\n",
        "encodings_512 = pca.fit_transform(encodings, labels)\n",
        "print(np.sum(pca.explained_variance_ratio_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.991135501545363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTCktWWlBtkb"
      },
      "source": [
        "Split our data, to get a test sample that we can evaluate our models on. We'll also load in our two classifiers in this cell\n",
        "\n",
        "\n",
        "\n",
        "> Both these models were trained on the same train test split as below, however, due to the quadratic runtime complexity of SVMs, coupled with 24 hour limits on Google Colab runtimes, we only used about half of the data, 80000 rows and then did a train test split on that of 0.2 and so we trained on 64000 rows.\n",
        "\n",
        "> Hyperparameter tuning was done through sklearn's `GridSearchCV` library to obtain an optimal set of parameters for both models\n",
        "\n",
        "> Due to the imbalance in our training data i.e, we have a lot of neutral, positive and negative tweets but very few very postive and very negative tweets both models are *balanced* in that they use the y values to automatically asjust class weights inversely proportional to class frequencies in the input data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iwHlz1a8BNQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import load\n",
        "\n",
        "_, X_test, _, y_test = train_test_split(encodings_512, \n",
        "                                        labels, \n",
        "                                        test_size=0.2, \n",
        "                                        random_state=0)\n",
        "clf = load('./svm_models/rbf_80000_5_balanced.joblib')\n",
        "ovr_clf = load('./svm_models/ovr_rbf_80000_5_balanced.joblib')\n",
        "gcv_clf = load('./svm_models/rbf_80000_5_balanced_gcv.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PvQhZeUESfM"
      },
      "source": [
        "Evaluate both models, f1 score and the confusion matrix are key here since our dataset is imbalanced. We also wrote a per class accuracy function to see how well the models do on each of the classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cCK7uE1Xbce"
      },
      "source": [
        "Sklearn's SVC implementation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwLvNP3gLAkC"
      },
      "source": [
        "labels_map = {\n",
        "    '0': 'Very Negative =====>',\n",
        "    '1': 'Negative ==========>',\n",
        "    '2': 'Neutral ===========>',\n",
        "    '3': 'Positive ==========>',\n",
        "    '4': 'Very Positive =====>'\n",
        "}\n",
        "\n",
        "def accuracy_per_class():\n",
        "  for label in range(5):\n",
        "    print(labels_map[str(label)], \n",
        "          sum([1 if x == label and y_test[idx] == y_pred[idx] else 0 for idx, x in enumerate(y_test)])/sum([1 if x == label else 0 for x in y_test]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TCWLDCo9FZL",
        "outputId": "dff3132c-870b-448a-be9f-83e36723fbe5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy_per_class()\n",
        "print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Very Negative =====> 0.6061053668143771\n",
            "Negative ==========> 0.6276931521888294\n",
            "Neutral ===========> 0.6855861702755325\n",
            "Positive ==========> 0.5600047670122751\n",
            "Very Positive =====> 0.6671652954375468\n",
            "f1 score:  0.6440708727297854\n",
            "accuracy:  0.6404157291331833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1231,   633,   129,    32,     6],\n",
              "       [  962,  4574,  1409,   315,    27],\n",
              "       [  286,  2738, 11620,  2140,   165],\n",
              "       [   67,   529,  1853,  4699,  1243],\n",
              "       [    8,    62,   117,   703,  1784]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhjL_zA_Xone"
      },
      "source": [
        "Sklearn's SVC implementation with One vs Rest Classifier wrapped around it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfi2BDlpAW9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f4003f-e793-4bbc-fec1-12b48534615c"
      },
      "source": [
        "y_pred = ovr_clf.predict(X_test)\n",
        "accuracy_per_class()\n",
        "print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Very Negative =====> 0.3495814869522403\n",
            "Negative ==========> 0.7053657197749417\n",
            "Neutral ===========> 0.7301315711841406\n",
            "Positive ==========> 0.66821594565606\n",
            "Very Positive =====> 0.4760658189977562\n",
            "f1 score:  0.6711504005013004\n",
            "accuracy:  0.6724793742633666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  710,  1162,   128,    29,     2],\n",
              "       [  313,  5140,  1551,   268,    15],\n",
              "       [   88,  2399, 12375,  2017,    70],\n",
              "       [   14,   418,  1827,  5607,   525],\n",
              "       [    1,    46,   103,  1251,  1273]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jLBPqB2Xyse"
      },
      "source": [
        "Sklearn's SVC implementation with optimal hyperparameter tuning through GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uihWFbruK8rj",
        "outputId": "c3504451-a21d-49b4-cef4-415a9a059f1e"
      },
      "source": [
        "y_pred = gcv_clf.predict(X_test)\n",
        "accuracy_per_class()\n",
        "print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Very Negative =====> 0.5790251107828656\n",
            "Negative ==========> 0.6652943598188555\n",
            "Neutral ===========> 0.7357956221605995\n",
            "Positive ==========> 0.6223334525086403\n",
            "Very Positive =====> 0.6406133133881825\n",
            "f1 score:  0.6827167160695405\n",
            "accuracy:  0.6811850423229401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1176,   690,   138,    25,     2],\n",
              "       [  712,  4848,  1522,   189,    16],\n",
              "       [  220,  2227, 12471,  1922,   109],\n",
              "       [   33,   326,  1846,  5222,   964],\n",
              "       [    5,    34,   129,   793,  1713]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WV-UM2xHvqf"
      },
      "source": [
        "## One vs One Classifiers\n",
        "\n",
        "Like ovr, ovo splits a multi-class classification problem into binary classification problems. We basically pit one dataset of each class against every other class individually.\n",
        "\n",
        "For example in our case we split it as follows:\n",
        "* Classifier 1 - *Very Positive vs Positive*\n",
        "* Classifier 2 - *Very Positive vs Neutral*\n",
        "* Classifier 3 - *Very Positive vs Negative*\n",
        "* Classifier 4 - *Very Positive vs Very Negative*\n",
        "* Classifier 5 - *Positive vs Negative*\n",
        "* Classifier 6 - *Positive vs Neutral*\n",
        "* Classifier 7 - *Positive vs Very Negative*\n",
        "* Classifier 8 - *Neutral vs Negative*\n",
        "* Classifier 9 - *Neutral vs Very Negative*\n",
        "* Classifier 10 - *Negative vs Very Negative*\n",
        "\n",
        "So we have ten binary classifiers in total. Each classifier predicts one class label and the label with the most number of predictions is predicted\n",
        "\n",
        "Total Number of Classifiers = `(NumClasses * (NumClasses â€“ 1)) / 2`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGj5or3LJxLQ"
      },
      "source": [
        "The cells below follow the same procedure as above for ovr to load and evaluate our ovo classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7aFzlyfJ6bC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beea4e6d-f384-4214-acf7-c8c857078e6d"
      },
      "source": [
        "ovo_clf = load('./svm_models/rbf_80000_5_balanced_gcv_ovo.joblib')\n",
        "y_pred = ovo_clf.predict(X_test)\n",
        "accuracy_per_class()\n",
        "print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Very Negative =====> 0.5839487936976858\n",
            "Negative ==========> 0.6620008233841087\n",
            "Neutral ===========> 0.7326095934863414\n",
            "Positive ==========> 0.6305565486831128\n",
            "Very Positive =====> 0.6637995512341062\n",
            "f1 score:  0.6846970183227786\n",
            "accuracy:  0.6828726025929498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1186,   689,   133,    20,     3],\n",
              "       [  755,  4824,  1505,   193,    10],\n",
              "       [  204,  2248, 12417,  1974,   106],\n",
              "       [   25,   322,  1774,  5291,   979],\n",
              "       [    2,    36,   122,   739,  1775]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9z1MRnLhvas"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMJSkhz4h0af"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbVCH_7SiyUK"
      },
      "source": [
        "All the above models followed the same process below during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tZE1vaQhz2U"
      },
      "source": [
        "# WARNING: This cell takes a long time to run \n",
        "# even when using GPUs and High RAM Runtimes\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import dump\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(encodings_512[:80000], \n",
        "                                                    labels[:80000], \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=0)\n",
        "# Optimal SVC hyperparameters obtained through GridSearchCV\n",
        "clf = make_pipeline(\n",
        "    StandardScaler(), \n",
        "    SVC(C=10, \n",
        "        gamma=0.001, \n",
        "        random_state=0, \n",
        "        class_weight='balanced'))\n",
        "clf.fit(X_train, y_train)\n",
        "dump(clf, './svm_models/rbf_80000_5_balanced_gcv.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ic2zYD9i6nz"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T_f-sL1jBWy"
      },
      "source": [
        "Sklearn's GridSearchCV Library came in handy with automated search for optimal hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj4HRJHEjMIn"
      },
      "source": [
        "# defining parameter range \n",
        "clf = make_pipeline(StandardScaler(),\n",
        "                    SVC(random_state=0, class_weight='balanced'))\n",
        "param_grid = {'svc__C': [0.1, 1, 10, 100, 1000],\n",
        "              'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf']}  \n",
        "  \n",
        "grid = GridSearchCV(clf, param_grid, refit = True, verbose = 3) \n",
        "  \n",
        "# fitting the model for grid search \n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_) \n",
        "print(grid.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}